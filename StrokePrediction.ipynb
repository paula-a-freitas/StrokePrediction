{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6a54dc",
   "metadata": {},
   "source": [
    "# Starting Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed12e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\panf\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\panf\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\panf\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23af694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b3d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"mySparkApp\") # Nome da aplicação Spark\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95d7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"mySparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06be6481",
   "metadata": {},
   "source": [
    "# Analyzing the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78e724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[0: int, gender: string, age: double, hypertension: int, heart_disease: int, ever_married: string, work_type: string, Residence_type: string, avg_glucose_level: double, bmi: double, smoking_status: string, stroke: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract Data\n",
    "\n",
    "df = spark.read.csv('C:\\desafio\\coleta_dados_estruturados\\Modulo 2 - Cientista de dados\\stroke_data.csv', header=True, inferSchema=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d9d5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many records are there in the file?\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa85b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many columns are there in the file? How many are numerical?\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113a1e9",
   "metadata": {},
   "source": [
    "# Analyzing the database\n",
    "Using API Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d5dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|40287|\n",
      "|     0|26848|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In the data set, how many patients had and did not have a stroke? (stroke: 1 if the patient had a stroke or 0 if not)\n",
    "\n",
    "df.groupBy('stroke').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cca2f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-----+\n",
      "|stroke|    work_type|count|\n",
      "+------+-------------+-----+\n",
      "|     1|     children|  520|\n",
      "|     1| Never_worked|   85|\n",
      "|     1|Self-employed|10807|\n",
      "|     1|     Govt_job| 5164|\n",
      "|     1|      Private|23711|\n",
      "+------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many stroke patients worked in the private sector, independently, in government and how many are children?\n",
    "\n",
    "df_filter = df.filter(df[\"stroke\"] == 1)\n",
    "df_filter.groupBy('stroke', 'work_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983d8d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|Female|39530|\n",
      "| Other|   11|\n",
      "|  Male|27594|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Determine the proportion, by gender of study participants\n",
    "\n",
    "df.groupBy('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7fd74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|hypertension|       avg(stroke)|\n",
      "+------------+------------------+\n",
      "|           1|0.8003086139602432|\n",
      "|           0|0.5607826365871913|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Who is more likely to have a stroke: hypertensive or non-hypertensive?\n",
    "\n",
    "df.groupBy('hypertension').agg({\"stroke\": \"avg\"}).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f416d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age|count|\n",
      "+----+-----+\n",
      "|79.0| 2916|\n",
      "|78.0| 2279|\n",
      "|80.0| 1858|\n",
      "|81.0| 1738|\n",
      "|82.0| 1427|\n",
      "|77.0|  994|\n",
      "|74.0|  987|\n",
      "|63.0|  942|\n",
      "|76.0|  892|\n",
      "|70.0|  881|\n",
      "|66.0|  848|\n",
      "|75.0|  809|\n",
      "|67.0|  801|\n",
      "|57.0|  775|\n",
      "|73.0|  759|\n",
      "|65.0|  716|\n",
      "|72.0|  709|\n",
      "|68.0|  688|\n",
      "|69.0|  677|\n",
      "|71.0|  667|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The number of people who have had a stroke by age\n",
    "\n",
    "df_filter2 = df.filter(df[\"stroke\"] == 1)\n",
    "df_filter2.groupBy('age').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26abd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28938"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of people who have had a stroke by age 50\n",
    "\n",
    "df_age50 = df[(df[\"age\"] > 50) & (df[\"stroke\"] == 1)]\n",
    "df_age50.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6653ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------+\n",
      "|stroke|avg(avg_glucose_level)|\n",
      "+------+----------------------+\n",
      "|     1|    119.95307046938272|\n",
      "|     0|    103.60273130214506|\n",
      "+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The average glucose level for people who have had and have not had a stroke\n",
    "\n",
    "df.groupBy('stroke').agg({\"avg_glucose_level\": \"avg\"}).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0909dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|stroke|          avg(bmi)|\n",
      "+------+------------------+\n",
      "|     1|29.942490629729495|\n",
      "|     0|27.989678933253657|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The average BMI (BMI = body mass index) of those who have had and have not had a stroke\n",
    "\n",
    "df.groupBy('stroke').agg({\"bmi\": \"avg\"}).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ab0c1",
   "metadata": {},
   "source": [
    "# Analyzing the database\n",
    "Using SQL Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d2c302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|stroke|count(1)|\n",
      "+------+--------+\n",
      "|     1|   40287|\n",
      "|     0|   26848|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In the data set, how many patients had and did not have a stroke? (stroke: 1 if the patient had a stroke or 0 if not)\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_table\")\n",
    "spark.sql(\"SELECT stroke, count(*) FROM stroke_table GROUP BY stroke\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9819e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|    work_type|count(1)|\n",
      "+-------------+--------+\n",
      "| Never_worked|      85|\n",
      "|Self-employed|   10807|\n",
      "|      Private|   23711|\n",
      "|     children|     520|\n",
      "|     Govt_job|    5164|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many stroke patients worked in the private sector, independently, in government and how many are children?\n",
    "\n",
    "df.createOrReplaceTempView(\"work_table\")\n",
    "spark.sql(\"SELECT work_type, count(*) FROM work_table WHERE stroke=1 GROUP BY work_type\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146e494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|count(1)|\n",
      "+------+--------+\n",
      "|Female|   39530|\n",
      "| Other|      11|\n",
      "|  Male|   27594|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Determine the proportion, by gender of study participants\n",
    "\n",
    "df.createOrReplaceTempView(\"gender_table\")\n",
    "spark.sql(\"SELECT gender, count(*) FROM gender_table GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c00a5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              prob|\n",
      "+------------------+\n",
      "|0.8003086139602432|\n",
      "|0.5607826365871913|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Who is more likely to have a stroke: hypertensive or non-hypertensive?\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_hypertension_table\")\n",
    "spark.sql(\"SELECT AVG(stroke) as prob FROM stroke_hypertension_table Group BY hypertension\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b105cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "| age|total_stroke|\n",
      "+----+------------+\n",
      "|79.0|        2916|\n",
      "|78.0|        2279|\n",
      "|80.0|        1858|\n",
      "|81.0|        1738|\n",
      "|82.0|        1427|\n",
      "|77.0|         994|\n",
      "|74.0|         987|\n",
      "|63.0|         942|\n",
      "|76.0|         892|\n",
      "|70.0|         881|\n",
      "|66.0|         848|\n",
      "|75.0|         809|\n",
      "|67.0|         801|\n",
      "|57.0|         775|\n",
      "|73.0|         759|\n",
      "|65.0|         716|\n",
      "|72.0|         709|\n",
      "|68.0|         688|\n",
      "|69.0|         677|\n",
      "|71.0|         667|\n",
      "+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The number of people who have had a stroke by age\n",
    "df.createOrReplaceTempView(\"stroke_age_table\")\n",
    "\n",
    "spark.sql(\"SELECT age, count(*) as total_stroke FROM stroke_age_table WHERE stroke=1 GROUP BY age ORDER BY total_stroke DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80fe78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|total_stroke50|\n",
      "+--------------+\n",
      "|         28938|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The number of people who have had a stroke by age 50\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_age50_table\")\n",
    "\n",
    "spark.sql(\"SELECT sum(CASE WHEN stroke = 1 AND age > 50 THEN 1 ELSE 0 END) as total_stroke50 FROM stroke_age50_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08252c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              prob|\n",
      "+------------------+\n",
      "|119.95307046938272|\n",
      "|103.60273130214506|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The average glucose level for people who have had and have not had a stroke\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_glucose_table\")\n",
    "spark.sql(\"SELECT AVG(avg_glucose_level) as prob FROM stroke_glucose_table GROUP BY stroke\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "623f01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              prob|\n",
      "+------------------+\n",
      "|29.942490629729495|\n",
      "|27.989678933253657|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The average BMI (BMI = body mass index) of those who have had and have not had a stroke\n",
    "\n",
    "df.createOrReplaceTempView(\"stroke_bmi_table\")\n",
    "spark.sql(\"SELECT AVG(bmi) as prob FROM stroke_bmi_table GROUP BY stroke\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a2332",
   "metadata": {},
   "source": [
    "# Analytics with Spark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742dc2b4",
   "metadata": {},
   "source": [
    "Create a decision tree model that predicts the chance of stroke from the continuous/categorical variables: age, BMI, hypertension, heart disease, mean glucose level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0992e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vector to prepare the data to train a machine learning model in Spark. \n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d0d6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Decision Tree Classifier\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(labelCol='stroke', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c1428eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Pipeline\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda28199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random selection of test data\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5ef06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictStrokeModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ff4d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = df.agg({'age':'mean', 'bmi':'mean', 'hypertension':'mean', 'heart_disease':'mean', 'avg_glucose_level':'mean'}).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43810e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[0: int, gender: string, age: double, hypertension: int, heart_disease: int, ever_married: string, work_type: string, Residence_type: string, avg_glucose_level: double, bmi: double, smoking_status: string, stroke: int, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating the test dataframe\n",
    "\n",
    "predictions = predictStrokeModel.transform(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91ae58cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.684379065345742"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the accuracy of machine learning model responses\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'stroke', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638e22e",
   "metadata": {},
   "source": [
    "Add to the decision tree model  the categorical variables to the model: gender and smoking status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a454754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating index for categorical variables\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "gender_indexer = StringIndexer(inputCol = 'gender', outputCol = 'GenderIndexer')\n",
    "gender_encoder = OneHotEncoder(inputCol = 'GenderIndexer', outputCol = 'GenderVector')\n",
    "\n",
    "smoke_indexer = StringIndexer(inputCol = 'smoking_status', outputCol = 'SmokeIndexer')\n",
    "smoke_encoder = OneHotEncoder(inputCol = 'SmokeIndexer', outputCol = 'SmokeVector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4dabd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vector to prepare the data to train a machine learning model in Spark. \n",
    "\n",
    "assembler = VectorAssembler(inputCols=['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'GenderVector', 'SmokeVector'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7ecc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gender_indexer,gender_encoder, smoke_indexer, smoke_encoder, assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cd73fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(labelCol='stroke', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e099142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8317062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictStrokeModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3123fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = df.agg({'age':'mean', 'bmi':'mean', 'hypertension':'mean', 'heart_disease':'mean', 'avg_glucose_level':'mean','gender':'mean', 'smoking_status':'mean'}).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63011e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[0: int, gender: string, age: double, hypertension: int, heart_disease: int, ever_married: string, work_type: string, Residence_type: string, avg_glucose_level: double, bmi: double, smoking_status: string, stroke: int, GenderIndexer: double, GenderVector: vector, SmokeIndexer: double, SmokeVector: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating the new test dataframe\n",
    "\n",
    "predictions = predictStrokeModel.transform(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2b6b37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350505201333931"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the accuracy of machine learning model responses\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'stroke', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0c196ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating how many levels the decision tree has\n",
    "\n",
    "decisionTreeModel = predictStrokeModel.stages[-1]\n",
    "decisionTreeModel.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10b57ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'bmi',\n",
       " 'hypertension',\n",
       " 'heart_disease',\n",
       " 'avg_glucose_level',\n",
       " 'GenderVector',\n",
       " 'SmokeVector']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler.getInputCols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6887f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(9, {0: 0.1718, 1: 0.001, 4: 0.0066, 7: 0.4809, 8: 0.3398})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyzing the importance of variables for the accuracy of the decision model\n",
    "\n",
    "decisionTreeModel.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a594a3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 0.17181653294336569),\n",
       " ('bmi', 0.0009543131655798752),\n",
       " ('hypertension', 0.0),\n",
       " ('heart_disease', 0.0),\n",
       " ('avg_glucose_level', 0.006561802302894585),\n",
       " ('GenderVector', 0.0),\n",
       " ('SmokeVector', 0.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyzing the importance of variables for the accuracy of the decision model\n",
    "\n",
    "list(zip(assembler.getInputCols(), decisionTreeModel.featureImportances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3",
   "language": "python",
   "name": "3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
